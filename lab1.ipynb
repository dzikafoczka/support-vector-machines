{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Laboratoria 1 - perceptron, neuron sigmoidalny"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30edc6bea24bfa0c"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:52:59.916916700Z",
     "start_time": "2024-03-20T10:52:59.812569400Z"
    }
   },
   "id": "2a71c558ef1d5f58"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dane"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcc864568a70ab9f"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "AND_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "AND_labels = np.array([0, 0, 0, 1])\n",
    "OR_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "OR_labels = np.array([0, 1, 1, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:00.021757Z",
     "start_time": "2024-03-20T10:52:59.825171200Z"
    }
   },
   "id": "8d4e61d20588cc32"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funkcje aktywacji"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17878919fd2c964"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def heaviside(x, threshold=0):\n",
    "    return (x > threshold).astype(float)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)    \n",
    "\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    return np.maximum(alpha * x, x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:00.042352600Z",
     "start_time": "2024-03-20T10:52:59.840202100Z"
    }
   },
   "id": "7e8c7776952753ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96b3717597152ce5"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \"\"\"\n",
    "    Perceptron model for binary classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, learning_rate=0.1, seed=0, random_weights=False, random_bias=False, random_distribution='uniform', activation_function=heaviside):\n",
    "        \"\"\"\n",
    "        :param input_size: number of input features\n",
    "        :param learning_rate: learning rate hyperparameter (default: 0.1)\n",
    "        :param seed: random seed for reproducibility (default: 0)\n",
    "        :param random_weights: if True, initializes weights with random values (default: False)\n",
    "        :param random_bias: if True, initializes bias with random values (default: False)\n",
    "        :param random_distribution: specify random distribution for weights and bias - 'normal' or 'uniform' (default: 'uniform')\n",
    "        :param activation_function: activation function (default: heaviside)\n",
    "        Perceptron initialization method.\n",
    "        \"\"\"\n",
    "        \n",
    "        # seed for reproducibility\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "        \n",
    "        # weights\n",
    "        if random_weights:\n",
    "            if random_distribution == 'uniform':\n",
    "                self.weights = self.rng.uniform(low=-0.1, high=0.1, size=input_size)\n",
    "            elif random_distribution == 'normal':\n",
    "                self.weights = self.rng.normal(loc=0, scale=1, size=input_size)\n",
    "        else:\n",
    "            self.weights = np.zeros(shape=input_size)\n",
    "        \n",
    "        # bias\n",
    "        if random_bias:\n",
    "            if random_distribution == 'uniform':\n",
    "                self.bias = self.rng.uniform(low=-0.1, high=0.1, size=1)\n",
    "            elif random_distribution == 'normal':\n",
    "                self.bias = self.rng.normal(loc=0, scale=1, size=1)\n",
    "        else:\n",
    "            self.bias = np.zeros(shape=1)\n",
    "            \n",
    "        # activation function\n",
    "        self.activation_function = activation_function\n",
    "        \n",
    "        # hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        :param inputs: inputs to predict (numpy array)\n",
    "        :return: numpy array of predictions (0 or 1)\n",
    "        \"\"\"\n",
    "        return self.activation_function(np.matmul(inputs, self.weights.T) + self.bias)\n",
    "    \n",
    "    def train(self, training_inputs, training_labels, epochs=1):\n",
    "        \"\"\"\n",
    "        :param training_inputs: training data (numpy array)\n",
    "        :param training_labels: training labels (numpy array)\n",
    "        :param epochs: number of epochs (default: 1)\n",
    "        Trains the perceptron model using the training data.\n",
    "        \"\"\"\n",
    "        \n",
    "        # training loop\n",
    "        for epoch in range(epochs):\n",
    "            for inputs, label in zip(training_inputs, training_labels):\n",
    "                y_pred = self.predict(inputs)\n",
    "                error = label - y_pred\n",
    "                self.weights += self.learning_rate * error * inputs\n",
    "                self.bias += self.learning_rate * error"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:00.045387400Z",
     "start_time": "2024-03-20T10:52:59.860434800Z"
    }
   },
   "id": "ea23ad7e17152bc9"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wagi: [0.2 0.1]\n",
      "Bias: [-0.2]\n",
      "Predykcje: [0. 0. 0. 1.]\n",
      "Wartości oczekiwane: [0 0 0 1]\n",
      "\n",
      "Wagi: [0.1 0.1]\n",
      "Bias: [0.]\n",
      "Predykcje: [0. 1. 1. 1.]\n",
      "Wartości oczekiwane: [0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# AND\n",
    "model_and = Perceptron(2, learning_rate=0.1)\n",
    "model_and.train(AND_inputs, AND_labels, epochs=5)\n",
    "\n",
    "print(f\"Wagi: {model_and.weights}\")\n",
    "print(f\"Bias: {model_and.bias}\")\n",
    "print(f\"Predykcje: {model_and.predict(AND_inputs)}\")\n",
    "print(f\"Wartości oczekiwane: {AND_labels}\\n\")\n",
    "\n",
    "# OR\n",
    "model_or = Perceptron(2, learning_rate=0.1)\n",
    "model_or.train(OR_inputs, OR_labels, epochs=5)\n",
    "\n",
    "print(f\"Wagi: {model_or.weights}\")\n",
    "print(f\"Bias: {model_or.bias}\")\n",
    "print(f\"Predykcje: {model_or.predict(OR_inputs)}\")\n",
    "print(f\"Wartości oczekiwane: {OR_labels}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:00.061167900Z",
     "start_time": "2024-03-20T10:52:59.872089400Z"
    }
   },
   "id": "22b69bc7a4a47211"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testy na bramkach logicznych AND i OR"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dee0360649f2ff1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Różne wartości learning rate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5287122356e0a5da"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# od bardzo małych do bardzo dużych wartości\n",
    "learning_rates = [0.00001, 0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 3.0, 5.0, 7.0, 9.0, 10.0, 30.0, 50.0, 70.0, 90.0, 100.0, 300.0, 500.0, 700.0, 900.0, 1000.0]\n",
    "\n",
    "# columns for the dataframe\n",
    "columns=['gate', 'activation function', 'learning_rate', 'epochs' , 'weights', 'bias', 'predictions', 'expected', 'errors']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:00.062170200Z",
     "start_time": "2024-03-20T10:52:59.888894300Z"
    }
   },
   "id": "95de27f3a68e7b93"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "   gate activation function  learning_rate epochs           weights  \\\n0   AND           heaviside        0.00001      5    [2e-05, 1e-05]   \n1   AND           heaviside        0.00010      5  [0.0002, 0.0001]   \n2   AND           heaviside        0.00100      5    [0.002, 0.001]   \n3   AND           heaviside        0.01000      5      [0.02, 0.01]   \n4   AND           heaviside        0.10000      5        [0.2, 0.1]   \n5   AND           heaviside        0.30000      5        [0.6, 0.3]   \n6   AND           heaviside        0.50000      5        [1.0, 0.5]   \n7   AND           heaviside        0.70000      5        [1.4, 0.7]   \n8   AND           heaviside        0.90000      5        [1.8, 0.9]   \n9   AND           heaviside        1.00000      5        [2.0, 1.0]   \n10  AND           heaviside        3.00000      5        [6.0, 3.0]   \n11  AND           heaviside        5.00000      5       [10.0, 5.0]   \n12  AND           heaviside        7.00000      5       [14.0, 7.0]   \n13  AND           heaviside        9.00000      5       [18.0, 9.0]   \n14  AND           heaviside       10.00000      5      [20.0, 10.0]   \n15  AND           heaviside       30.00000      5      [60.0, 30.0]   \n16  AND           heaviside       50.00000      5     [100.0, 50.0]   \n17  AND           heaviside       70.00000      5     [140.0, 70.0]   \n18  AND           heaviside       90.00000      5     [180.0, 90.0]   \n19  AND           heaviside      100.00000      5    [200.0, 100.0]   \n20  AND           heaviside      300.00000      5    [600.0, 300.0]   \n21  AND           heaviside      500.00000      5   [1000.0, 500.0]   \n22  AND           heaviside      700.00000      5   [1400.0, 700.0]   \n23  AND           heaviside      900.00000      5   [1800.0, 900.0]   \n24  AND           heaviside     1000.00000      5  [2000.0, 1000.0]   \n\n         bias           predictions      expected                errors  \n0    [-2e-05]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n1   [-0.0002]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n2    [-0.002]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n3     [-0.02]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n4      [-0.2]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n5      [-0.6]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n6      [-1.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n7      [-1.4]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n8      [-1.8]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n9      [-2.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n10     [-6.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n11    [-10.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n12    [-14.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n13    [-18.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n14    [-20.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n15    [-60.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n16   [-100.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n17   [-140.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n18   [-180.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n19   [-200.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n20   [-600.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n21  [-1000.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n22  [-1400.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n23  [-1800.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n24  [-2000.0]  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gate</th>\n      <th>activation function</th>\n      <th>learning_rate</th>\n      <th>epochs</th>\n      <th>weights</th>\n      <th>bias</th>\n      <th>predictions</th>\n      <th>expected</th>\n      <th>errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.00001</td>\n      <td>5</td>\n      <td>[2e-05, 1e-05]</td>\n      <td>[-2e-05]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.00010</td>\n      <td>5</td>\n      <td>[0.0002, 0.0001]</td>\n      <td>[-0.0002]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.00100</td>\n      <td>5</td>\n      <td>[0.002, 0.001]</td>\n      <td>[-0.002]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.01000</td>\n      <td>5</td>\n      <td>[0.02, 0.01]</td>\n      <td>[-0.02]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.10000</td>\n      <td>5</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.30000</td>\n      <td>5</td>\n      <td>[0.6, 0.3]</td>\n      <td>[-0.6]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.50000</td>\n      <td>5</td>\n      <td>[1.0, 0.5]</td>\n      <td>[-1.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.70000</td>\n      <td>5</td>\n      <td>[1.4, 0.7]</td>\n      <td>[-1.4]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.90000</td>\n      <td>5</td>\n      <td>[1.8, 0.9]</td>\n      <td>[-1.8]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>1.00000</td>\n      <td>5</td>\n      <td>[2.0, 1.0]</td>\n      <td>[-2.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>3.00000</td>\n      <td>5</td>\n      <td>[6.0, 3.0]</td>\n      <td>[-6.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>5.00000</td>\n      <td>5</td>\n      <td>[10.0, 5.0]</td>\n      <td>[-10.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>7.00000</td>\n      <td>5</td>\n      <td>[14.0, 7.0]</td>\n      <td>[-14.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>9.00000</td>\n      <td>5</td>\n      <td>[18.0, 9.0]</td>\n      <td>[-18.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>10.00000</td>\n      <td>5</td>\n      <td>[20.0, 10.0]</td>\n      <td>[-20.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>30.00000</td>\n      <td>5</td>\n      <td>[60.0, 30.0]</td>\n      <td>[-60.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>50.00000</td>\n      <td>5</td>\n      <td>[100.0, 50.0]</td>\n      <td>[-100.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>70.00000</td>\n      <td>5</td>\n      <td>[140.0, 70.0]</td>\n      <td>[-140.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>90.00000</td>\n      <td>5</td>\n      <td>[180.0, 90.0]</td>\n      <td>[-180.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>100.00000</td>\n      <td>5</td>\n      <td>[200.0, 100.0]</td>\n      <td>[-200.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>300.00000</td>\n      <td>5</td>\n      <td>[600.0, 300.0]</td>\n      <td>[-600.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>500.00000</td>\n      <td>5</td>\n      <td>[1000.0, 500.0]</td>\n      <td>[-1000.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>700.00000</td>\n      <td>5</td>\n      <td>[1400.0, 700.0]</td>\n      <td>[-1400.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>900.00000</td>\n      <td>5</td>\n      <td>[1800.0, 900.0]</td>\n      <td>[-1800.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>1000.00000</td>\n      <td>5</td>\n      <td>[2000.0, 1000.0]</td>\n      <td>[-2000.0]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AND\n",
    "df_lr_and = pd.DataFrame(columns=columns)\n",
    "for lr in learning_rates:\n",
    "    model_and = Perceptron(2, learning_rate=lr)\n",
    "    model_and.train(AND_inputs, AND_labels, epochs=5)\n",
    "    df_lr_and = df_lr_and._append({'gate': 'AND', 'activation function': heaviside.__name__, 'learning_rate': lr, 'epochs': 5, 'weights': model_and.weights, 'bias': model_and.bias, 'predictions': model_and.predict(AND_inputs), 'expected': AND_labels, 'errors': model_and.predict(AND_inputs) - AND_labels}, ignore_index=True)\n",
    "    \n",
    "df_lr_and"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:00.074917500Z",
     "start_time": "2024-03-20T10:52:59.904373900Z"
    }
   },
   "id": "aef0a50664a0430a"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "   gate activation function  learning_rate epochs           weights   bias  \\\n0    OR           heaviside        0.00001      5    [1e-05, 1e-05]  [0.0]   \n1    OR           heaviside        0.00010      5  [0.0001, 0.0001]  [0.0]   \n2    OR           heaviside        0.00100      5    [0.001, 0.001]  [0.0]   \n3    OR           heaviside        0.01000      5      [0.01, 0.01]  [0.0]   \n4    OR           heaviside        0.10000      5        [0.1, 0.1]  [0.0]   \n5    OR           heaviside        0.30000      5        [0.3, 0.3]  [0.0]   \n6    OR           heaviside        0.50000      5        [0.5, 0.5]  [0.0]   \n7    OR           heaviside        0.70000      5        [0.7, 0.7]  [0.0]   \n8    OR           heaviside        0.90000      5        [0.9, 0.9]  [0.0]   \n9    OR           heaviside        1.00000      5        [1.0, 1.0]  [0.0]   \n10   OR           heaviside        3.00000      5        [3.0, 3.0]  [0.0]   \n11   OR           heaviside        5.00000      5        [5.0, 5.0]  [0.0]   \n12   OR           heaviside        7.00000      5        [7.0, 7.0]  [0.0]   \n13   OR           heaviside        9.00000      5        [9.0, 9.0]  [0.0]   \n14   OR           heaviside       10.00000      5      [10.0, 10.0]  [0.0]   \n15   OR           heaviside       30.00000      5      [30.0, 30.0]  [0.0]   \n16   OR           heaviside       50.00000      5      [50.0, 50.0]  [0.0]   \n17   OR           heaviside       70.00000      5      [70.0, 70.0]  [0.0]   \n18   OR           heaviside       90.00000      5      [90.0, 90.0]  [0.0]   \n19   OR           heaviside      100.00000      5    [100.0, 100.0]  [0.0]   \n20   OR           heaviside      300.00000      5    [300.0, 300.0]  [0.0]   \n21   OR           heaviside      500.00000      5    [500.0, 500.0]  [0.0]   \n22   OR           heaviside      700.00000      5    [700.0, 700.0]  [0.0]   \n23   OR           heaviside      900.00000      5    [900.0, 900.0]  [0.0]   \n24   OR           heaviside     1000.00000      5  [1000.0, 1000.0]  [0.0]   \n\n             predictions      expected                errors  \n0   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n1   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n2   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n3   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n4   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n5   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n6   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n7   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n8   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n9   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n10  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n11  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n12  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n13  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n14  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n15  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n16  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n17  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n18  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n19  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n20  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n21  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n22  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n23  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n24  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gate</th>\n      <th>activation function</th>\n      <th>learning_rate</th>\n      <th>epochs</th>\n      <th>weights</th>\n      <th>bias</th>\n      <th>predictions</th>\n      <th>expected</th>\n      <th>errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.00001</td>\n      <td>5</td>\n      <td>[1e-05, 1e-05]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.00010</td>\n      <td>5</td>\n      <td>[0.0001, 0.0001]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.00100</td>\n      <td>5</td>\n      <td>[0.001, 0.001]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.01000</td>\n      <td>5</td>\n      <td>[0.01, 0.01]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.10000</td>\n      <td>5</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.30000</td>\n      <td>5</td>\n      <td>[0.3, 0.3]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.50000</td>\n      <td>5</td>\n      <td>[0.5, 0.5]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.70000</td>\n      <td>5</td>\n      <td>[0.7, 0.7]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.90000</td>\n      <td>5</td>\n      <td>[0.9, 0.9]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>1.00000</td>\n      <td>5</td>\n      <td>[1.0, 1.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>3.00000</td>\n      <td>5</td>\n      <td>[3.0, 3.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>5.00000</td>\n      <td>5</td>\n      <td>[5.0, 5.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>7.00000</td>\n      <td>5</td>\n      <td>[7.0, 7.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>9.00000</td>\n      <td>5</td>\n      <td>[9.0, 9.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>10.00000</td>\n      <td>5</td>\n      <td>[10.0, 10.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>30.00000</td>\n      <td>5</td>\n      <td>[30.0, 30.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>50.00000</td>\n      <td>5</td>\n      <td>[50.0, 50.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>70.00000</td>\n      <td>5</td>\n      <td>[70.0, 70.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>90.00000</td>\n      <td>5</td>\n      <td>[90.0, 90.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>100.00000</td>\n      <td>5</td>\n      <td>[100.0, 100.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>300.00000</td>\n      <td>5</td>\n      <td>[300.0, 300.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>500.00000</td>\n      <td>5</td>\n      <td>[500.0, 500.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>700.00000</td>\n      <td>5</td>\n      <td>[700.0, 700.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>900.00000</td>\n      <td>5</td>\n      <td>[900.0, 900.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>1000.00000</td>\n      <td>5</td>\n      <td>[1000.0, 1000.0]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR\n",
    "df_lr_or = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model_or = Perceptron(2, learning_rate=lr)\n",
    "    model_or.train(OR_inputs, OR_labels, epochs=3)\n",
    "    df_lr_or = df_lr_or._append({'gate': 'OR', 'activation function': heaviside.__name__, 'learning_rate': lr, 'epochs': 5, 'weights': model_or.weights, 'bias': model_or.bias, 'predictions': model_or.predict(OR_inputs), 'expected': OR_labels, 'errors': model_or.predict(OR_inputs) - OR_labels}, ignore_index=True)\n",
    "\n",
    "df_lr_or"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:00.075924300Z",
     "start_time": "2024-03-20T10:52:59.966521800Z"
    }
   },
   "id": "20740afc60ae64c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Różne ilości epok"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "851d9e27b5382cf3"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# od małych do bardzo dużych wartości\n",
    "epochs = [1, 2, 3, 4, 5, 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 1000, 2000, 3000, 4000, 5000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:00.076925100Z",
     "start_time": "2024-03-20T10:53:00.029148400Z"
    }
   },
   "id": "d5a0f6648776fd9f"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "   gate activation function  learning_rate epochs     weights    bias  \\\n0   AND           heaviside            0.1      1  [0.1, 0.1]   [0.1]   \n1   AND           heaviside            0.1      2  [0.2, 0.1]   [0.0]   \n2   AND           heaviside            0.1      3  [0.2, 0.1]  [-0.1]   \n3   AND           heaviside            0.1      4  [0.2, 0.2]  [-0.1]   \n4   AND           heaviside            0.1      5  [0.2, 0.1]  [-0.2]   \n5   AND           heaviside            0.1     10  [0.2, 0.1]  [-0.2]   \n6   AND           heaviside            0.1     20  [0.2, 0.1]  [-0.2]   \n7   AND           heaviside            0.1     30  [0.2, 0.1]  [-0.2]   \n8   AND           heaviside            0.1     40  [0.2, 0.1]  [-0.2]   \n9   AND           heaviside            0.1     50  [0.2, 0.1]  [-0.2]   \n10  AND           heaviside            0.1    100  [0.2, 0.1]  [-0.2]   \n11  AND           heaviside            0.1    200  [0.2, 0.1]  [-0.2]   \n12  AND           heaviside            0.1    300  [0.2, 0.1]  [-0.2]   \n13  AND           heaviside            0.1    400  [0.2, 0.1]  [-0.2]   \n14  AND           heaviside            0.1    500  [0.2, 0.1]  [-0.2]   \n15  AND           heaviside            0.1   1000  [0.2, 0.1]  [-0.2]   \n16  AND           heaviside            0.1   2000  [0.2, 0.1]  [-0.2]   \n17  AND           heaviside            0.1   3000  [0.2, 0.1]  [-0.2]   \n18  AND           heaviside            0.1   4000  [0.2, 0.1]  [-0.2]   \n19  AND           heaviside            0.1   5000  [0.2, 0.1]  [-0.2]   \n\n             predictions      expected                errors  \n0   [1.0, 1.0, 1.0, 1.0]  [0, 0, 0, 1]  [1.0, 1.0, 1.0, 0.0]  \n1   [0.0, 1.0, 1.0, 1.0]  [0, 0, 0, 1]  [0.0, 1.0, 1.0, 0.0]  \n2   [0.0, 0.0, 1.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 1.0, 0.0]  \n3   [0.0, 1.0, 1.0, 1.0]  [0, 0, 0, 1]  [0.0, 1.0, 1.0, 0.0]  \n4   [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n5   [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n6   [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n7   [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n8   [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n9   [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n10  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n11  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n12  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n13  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n14  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n15  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n16  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n17  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n18  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  \n19  [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]  [0.0, 0.0, 0.0, 0.0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gate</th>\n      <th>activation function</th>\n      <th>learning_rate</th>\n      <th>epochs</th>\n      <th>weights</th>\n      <th>bias</th>\n      <th>predictions</th>\n      <th>expected</th>\n      <th>errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>1</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.1]</td>\n      <td>[1.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[1.0, 1.0, 1.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>2</td>\n      <td>[0.2, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 1.0, 1.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>3</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.1]</td>\n      <td>[0.0, 0.0, 1.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 1.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>4</td>\n      <td>[0.2, 0.2]</td>\n      <td>[-0.1]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 1.0, 1.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>5</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>30</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>50</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>100</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>200</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>300</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>400</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>500</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>1000</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>2000</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>3000</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>4000</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>5000</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AND\n",
    "df_epochs_and = pd.DataFrame(columns=columns)\n",
    "\n",
    "for epoch in epochs:\n",
    "    model_and = Perceptron(2, learning_rate=0.1)\n",
    "    model_and.train(AND_inputs, AND_labels, epochs=epoch)\n",
    "    df_epochs_and = df_epochs_and._append({'gate': 'AND', 'activation function': heaviside.__name__, 'learning_rate': 0.1, 'epochs': epoch, 'weights': model_and.weights, 'bias': model_and.bias, 'predictions': model_and.predict(AND_inputs), 'expected': AND_labels, 'errors': model_and.predict(AND_inputs) - AND_labels}, ignore_index=True)\n",
    "    \n",
    "df_epochs_and"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:01.014533300Z",
     "start_time": "2024-03-20T10:53:00.045387400Z"
    }
   },
   "id": "d2dc23668222a453"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "   gate activation function  learning_rate epochs     weights   bias  \\\n0    OR           heaviside            0.1      1  [0.0, 0.1]  [0.1]   \n1    OR           heaviside            0.1      2  [0.1, 0.1]  [0.1]   \n2    OR           heaviside            0.1      3  [0.1, 0.1]  [0.0]   \n3    OR           heaviside            0.1      4  [0.1, 0.1]  [0.0]   \n4    OR           heaviside            0.1      5  [0.1, 0.1]  [0.0]   \n5    OR           heaviside            0.1     10  [0.1, 0.1]  [0.0]   \n6    OR           heaviside            0.1     20  [0.1, 0.1]  [0.0]   \n7    OR           heaviside            0.1     30  [0.1, 0.1]  [0.0]   \n8    OR           heaviside            0.1     40  [0.1, 0.1]  [0.0]   \n9    OR           heaviside            0.1     50  [0.1, 0.1]  [0.0]   \n10   OR           heaviside            0.1    100  [0.1, 0.1]  [0.0]   \n11   OR           heaviside            0.1    200  [0.1, 0.1]  [0.0]   \n12   OR           heaviside            0.1    300  [0.1, 0.1]  [0.0]   \n13   OR           heaviside            0.1    400  [0.1, 0.1]  [0.0]   \n14   OR           heaviside            0.1    500  [0.1, 0.1]  [0.0]   \n15   OR           heaviside            0.1   1000  [0.1, 0.1]  [0.0]   \n16   OR           heaviside            0.1   2000  [0.1, 0.1]  [0.0]   \n17   OR           heaviside            0.1   3000  [0.1, 0.1]  [0.0]   \n18   OR           heaviside            0.1   4000  [0.1, 0.1]  [0.0]   \n19   OR           heaviside            0.1   5000  [0.1, 0.1]  [0.0]   \n\n             predictions      expected                errors  \n0   [1.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [1.0, 0.0, 0.0, 0.0]  \n1   [1.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [1.0, 0.0, 0.0, 0.0]  \n2   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n3   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n4   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n5   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n6   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n7   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n8   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n9   [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n10  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n11  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n12  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n13  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n14  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n15  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n16  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n17  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n18  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  \n19  [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]  [0.0, 0.0, 0.0, 0.0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gate</th>\n      <th>activation function</th>\n      <th>learning_rate</th>\n      <th>epochs</th>\n      <th>weights</th>\n      <th>bias</th>\n      <th>predictions</th>\n      <th>expected</th>\n      <th>errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>1</td>\n      <td>[0.0, 0.1]</td>\n      <td>[0.1]</td>\n      <td>[1.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[1.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>2</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.1]</td>\n      <td>[1.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[1.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>3</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>4</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>5</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>10</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>20</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>30</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>40</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>50</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>100</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>200</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>300</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>400</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>500</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>1000</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>2000</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>3000</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>4000</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>5000</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR\n",
    "df_epochs_or = pd.DataFrame(columns=columns)\n",
    "\n",
    "for epoch in epochs:\n",
    "    model_or = Perceptron(2, learning_rate=0.1)\n",
    "    model_or.train(OR_inputs, OR_labels, epochs=epoch)\n",
    "    df_epochs_or = df_epochs_or._append({'gate': 'OR', 'activation function': heaviside.__name__, 'learning_rate': 0.1, 'epochs': epoch, 'weights': model_or.weights, 'bias': model_or.bias, 'predictions': model_or.predict(OR_inputs), 'expected': OR_labels, 'errors': model_or.predict(OR_inputs) - OR_labels}, ignore_index=True)\n",
    "    \n",
    "df_epochs_or"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:01.963247800Z",
     "start_time": "2024-03-20T10:53:01.011482Z"
    }
   },
   "id": "fb5fceebe07e8b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Różne funkcje aktywacji"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7819c9fb7dc07a9"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "activation_functions = [heaviside, sigmoid, relu, leaky_relu, tanh]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:01.988885300Z",
     "start_time": "2024-03-20T10:53:01.963247800Z"
    }
   },
   "id": "fa11aa287ba8ec98"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "  gate activation function  learning_rate epochs  \\\n0  AND           heaviside            0.1   1000   \n1  AND             sigmoid            0.1   1000   \n2  AND                relu            0.1   1000   \n3  AND          leaky_relu            0.1   1000   \n4  AND                tanh            0.1   1000   \n\n                                    weights                   bias  \\\n0                                [0.2, 0.1]                 [-0.2]   \n1    [5.602369772963133, 5.596276171199277]   [-8.567229481512781]   \n2  [0.9999999976810108, 0.9999999975378018]  [-0.9999999963841002]   \n3   [0.9844054567174376, 0.983430797763332]  [-0.9746588672583987]   \n4  [0.6458267921134033, 0.6146129071981778]  [-0.3229133960567015]   \n\n                 predictions      expected  \\\n0       [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]   \n1    [0.0, 0.05, 0.05, 0.93]  [0, 0, 0, 1]   \n2       [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]   \n3  [-0.01, 0.01, 0.01, 0.99]  [0, 0, 0, 1]   \n4  [-0.31, 0.28, 0.31, 0.73]  [0, 0, 0, 1]   \n\n                                       errors  \n0                        [0.0, 0.0, 0.0, 0.0]  \n1     [0.0, 0.05, 0.05, -0.06999999999999995]  \n2                        [0.0, 0.0, 0.0, 0.0]  \n3  [-0.01, 0.01, 0.01, -0.010000000000000009]  \n4                  [-0.31, 0.28, 0.31, -0.27]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gate</th>\n      <th>activation function</th>\n      <th>learning_rate</th>\n      <th>epochs</th>\n      <th>weights</th>\n      <th>bias</th>\n      <th>predictions</th>\n      <th>expected</th>\n      <th>errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>1000</td>\n      <td>[0.2, 0.1]</td>\n      <td>[-0.2]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.1</td>\n      <td>1000</td>\n      <td>[5.602369772963133, 5.596276171199277]</td>\n      <td>[-8.567229481512781]</td>\n      <td>[0.0, 0.05, 0.05, 0.93]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.05, 0.05, -0.06999999999999995]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AND</td>\n      <td>relu</td>\n      <td>0.1</td>\n      <td>1000</td>\n      <td>[0.9999999976810108, 0.9999999975378018]</td>\n      <td>[-0.9999999963841002]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AND</td>\n      <td>leaky_relu</td>\n      <td>0.1</td>\n      <td>1000</td>\n      <td>[0.9844054567174376, 0.983430797763332]</td>\n      <td>[-0.9746588672583987]</td>\n      <td>[-0.01, 0.01, 0.01, 0.99]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[-0.01, 0.01, 0.01, -0.010000000000000009]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AND</td>\n      <td>tanh</td>\n      <td>0.1</td>\n      <td>1000</td>\n      <td>[0.6458267921134033, 0.6146129071981778]</td>\n      <td>[-0.3229133960567015]</td>\n      <td>[-0.31, 0.28, 0.31, 0.73]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[-0.31, 0.28, 0.31, -0.27]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AND\n",
    "df_af_and = pd.DataFrame(columns=columns)\n",
    "\n",
    "for af in activation_functions:\n",
    "    model_and = Perceptron(2, learning_rate=0.1, activation_function=af)\n",
    "    model_and.train(AND_inputs, AND_labels, epochs=1000)\n",
    "    df_af_and = df_af_and._append({'gate': 'AND', 'activation function': af.__name__, 'learning_rate': 0.1, 'epochs': 1000, 'weights': model_and.weights, 'bias': model_and.bias, 'predictions': np.round(model_and.predict(AND_inputs), 2), 'expected': AND_labels, 'errors': np.round(model_and.predict(AND_inputs), 2) - AND_labels}, ignore_index=True)\n",
    "    \n",
    "df_af_and"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:02.242812600Z",
     "start_time": "2024-03-20T10:53:01.988885300Z"
    }
   },
   "id": "2a6fff97a5f2397d"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "  gate activation function  learning_rate epochs  \\\n0   OR           heaviside            0.1   2000   \n1   OR             sigmoid            0.1   2000   \n2   OR                relu            0.1   2000   \n3   OR          leaky_relu            0.1   2000   \n4   OR                tanh            0.1   2000   \n\n                                      weights                     bias  \\\n0                                  [0.1, 0.1]                    [0.0]   \n1      [8.207698543772604, 8.209640649850687]     [-3.636216228347191]   \n2  [0.44444444444444414, 0.47222222222222193]     [0.2777777777777781]   \n3  [0.44444444444444414, 0.47222222222222193]     [0.2777777777777781]   \n4     [3.3175174939326086, 3.318746020709793]  [0.0052209457622765226]   \n\n                predictions      expected  \\\n0      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]   \n1   [0.03, 0.99, 0.99, 1.0]  [0, 1, 1, 1]   \n2  [0.28, 0.75, 0.72, 1.19]  [0, 1, 1, 1]   \n3  [0.28, 0.75, 0.72, 1.19]  [0, 1, 1, 1]   \n4     [0.01, 1.0, 1.0, 1.0]  [0, 1, 1, 1]   \n\n                                              errors  \n0                               [0.0, 0.0, 0.0, 0.0]  \n1  [0.03, -0.010000000000000009, -0.0100000000000...  \n2          [0.28, -0.25, -0.28, 0.18999999999999995]  \n3          [0.28, -0.25, -0.28, 0.18999999999999995]  \n4                              [0.01, 0.0, 0.0, 0.0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gate</th>\n      <th>activation function</th>\n      <th>learning_rate</th>\n      <th>epochs</th>\n      <th>weights</th>\n      <th>bias</th>\n      <th>predictions</th>\n      <th>expected</th>\n      <th>errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.1</td>\n      <td>2000</td>\n      <td>[0.1, 0.1]</td>\n      <td>[0.0]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.1</td>\n      <td>2000</td>\n      <td>[8.207698543772604, 8.209640649850687]</td>\n      <td>[-3.636216228347191]</td>\n      <td>[0.03, 0.99, 0.99, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.03, -0.010000000000000009, -0.0100000000000...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>OR</td>\n      <td>relu</td>\n      <td>0.1</td>\n      <td>2000</td>\n      <td>[0.44444444444444414, 0.47222222222222193]</td>\n      <td>[0.2777777777777781]</td>\n      <td>[0.28, 0.75, 0.72, 1.19]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.28, -0.25, -0.28, 0.18999999999999995]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OR</td>\n      <td>leaky_relu</td>\n      <td>0.1</td>\n      <td>2000</td>\n      <td>[0.44444444444444414, 0.47222222222222193]</td>\n      <td>[0.2777777777777781]</td>\n      <td>[0.28, 0.75, 0.72, 1.19]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.28, -0.25, -0.28, 0.18999999999999995]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OR</td>\n      <td>tanh</td>\n      <td>0.1</td>\n      <td>2000</td>\n      <td>[3.3175174939326086, 3.318746020709793]</td>\n      <td>[0.0052209457622765226]</td>\n      <td>[0.01, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.01, 0.0, 0.0, 0.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR\n",
    "df_af_or = pd.DataFrame(columns=columns)\n",
    "\n",
    "for af in activation_functions:\n",
    "    model_or = Perceptron(2, learning_rate=0.1, activation_function=af)\n",
    "    model_or.train(OR_inputs, OR_labels, epochs=2000)\n",
    "    df_af_or = df_af_or._append({'gate': 'OR', 'activation function': af.__name__, 'learning_rate': 0.1, 'epochs': 2000, 'weights': model_or.weights, 'bias': model_or.bias, 'predictions': np.round(model_or.predict(OR_inputs), 2), 'expected': OR_labels, 'errors': np.round(model_or.predict(OR_inputs), 2) - OR_labels}, ignore_index=True)\n",
    "    \n",
    "df_af_or"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:02.873057Z",
     "start_time": "2024-03-20T10:53:02.244588Z"
    }
   },
   "id": "9b9ce60266f90076"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Wnioski\n",
    "Wartość `learning_rate` służy do określenia jak bardzo wagi i bias są aktualizowane w każdej iteracji. Dla małych wartości `learning_rate` model uczy się wolniej, ale może osiągnąć lepsze wyniki. Dla dużych wartości `learning_rate` model uczy się szybciej, ale może osiągnąć gorsze wyniki. Dla wartości `learning_rate` bliskich 0 model uczy się bardzo wolno, a dla wartości `learning_rate` bliskich 1 model uczy się bardzo szybko. Dla wartości `learning_rate` większych od 1 model może nie nauczyć się niczego, ponieważ aktualizacje wag i bias będą zbyt duże, co doprowadzi do sytuacji, w której nigdy nie dojdziemy do szukanego minimum.\n",
    "\n",
    "Niemniej jednak w przypadku prostego modelu pojedynczego perceptronu oraz zbioru uczącego AND i OR wartość `learning_rate` wpływa jedynie na ostateczną postać wagi i bias. Parametr ten wpływa na to, że wagi i bias są odpowiedno przeskalowane, ale dla dowolnej wartości `learning_rate` zawsze znajdziemy takie wagi i bias, które pozwolą na poprawne przewidywanie wartości dla bramek logicznych AND i OR.\n",
    "\n",
    "Wartość `epochs` służy do określenia ile razy model ma przejść przez cały zbiór uczący. Im większa wartość, tych więcej iteracji model ma na nauczenie się relacji zawartej w danych. \n",
    "\n",
    "W przypadku perceptronu dla bramek logicznych AND i OR wartość `epochs` nie ma znaczącego wpływu na wyniki, ponieważ model jest na tyle prosty, że jest w stanie nauczyć się relacji w danych w kilku iteracjach. Dla bardziej skomplikowanych modeli i zbiorów danych wartość `epochs` ma większe znaczenie, ponieważ model musi przejść przez zbiór uczący wielokrotnie, aby nauczyć się relacji w danych (i co ważne, nie przeuczyć się - liczba epok musi być tak dopasowana, aby nie wystąpiło zjawisko nadmiernego dopasowania). Z powyższych obserwacji wynika, że wartość `epochs` dla uczenia perceptronu bramek logicznych AND wynosząca 5 jest wystarczająca, by model nauczył się dawać poprawne predykcje, natomiast dla bramek logicznych OR jest to 3 (oczywiście przy powyższej implementacji i założeniach, funkcji aktywacji itd)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f861a769552dba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Neuron sigmoidalny"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d48bf6d9d619f75e"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class SigmoidNeuron:\n",
    "    \"\"\"\n",
    "    Sigmoid neuron model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, learning_rate=0.1, seed=0, activation_function=sigmoid):\n",
    "        \"\"\"\n",
    "        :param input_size: number of input features\n",
    "        :param learning_rate: learning rate hyperparameter (default: 0.1)\n",
    "        :param seed: random seed for reproducibility (default: 0)\n",
    "        :param activation_function: activation function (default: sigmoid)\n",
    "        Sigmoid neuron initialization method.\n",
    "        \"\"\"\n",
    "        \n",
    "        # seed for reproducibility\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "        \n",
    "        # weights\n",
    "        self.weights = self.rng.uniform(low=-0.1, high=0.1, size=input_size)\n",
    "        \n",
    "        # bias\n",
    "        self.bias = self.rng.uniform(low=-0.1, high=0.1, size=1)\n",
    "        \n",
    "        # hyperparameters\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # activation function\n",
    "        self.activation_function = activation_function\n",
    "    \n",
    "    def feedforward(self, inputs):\n",
    "        return self.activation_function(np.matmul(inputs, self.weights.T) + self.bias)\n",
    "    \n",
    "    def backpropagation(self, inputs, target):\n",
    "        # feedforward\n",
    "        predicted = self.feedforward(inputs)\n",
    "        \n",
    "        # error\n",
    "        error = predicted - target\n",
    "        \n",
    "        # derivative of the loss function with respect to the weights and bias\n",
    "        dC_dw = np.dot(inputs.T, error)\n",
    "        dC_db = np.sum(error)\n",
    "        \n",
    "        # update weights and bias\n",
    "        self.weights -= self.learning_rate * dC_dw\n",
    "        self.bias -= self.learning_rate * dC_db\n",
    "    \n",
    "    def loss(self, inputs, target):\n",
    "        # feedforward\n",
    "        prediction = self.feedforward(inputs)\n",
    "        \n",
    "        # loss\n",
    "        return 0.5 * np.square(prediction - target)\n",
    "    \n",
    "    def train(self, training_inputs, training_labels, epochs=1, verbose=False):\n",
    "        # train loop\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for inputs, target in zip(training_inputs, training_labels):\n",
    "                inputs = np.array(inputs, ndmin=2)\n",
    "                \n",
    "                # backpropagation\n",
    "                self.backpropagation(inputs, target)\n",
    "                \n",
    "                # epoch loss\n",
    "                total_loss += self.loss(inputs, target)\n",
    "                if verbose and (epoch + 1) % 100 == 0:\n",
    "                    print(f\"Epoch {epoch + 1}/{epochs}, total loss: {total_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:02.874336300Z",
     "start_time": "2024-03-20T10:53:02.854512300Z"
    }
   },
   "id": "ce0f00c3aae8fe7d"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wagi: [5.60282667 5.59673575]\n",
      "Bias: [-8.56791652]\n",
      "Predykcje: [1.90072190e-04 4.87449428e-02 4.90281494e-02 9.32870694e-01]\n",
      "Wartości oczekiwane: [0 0 0 1]\n",
      "\n",
      "Wagi: [6.78425253 6.78810429]\n",
      "Bias: [-2.91436951]\n",
      "Predykcje: [0.05144778 0.97964243 0.97956547 0.99997649]\n",
      "Wartości oczekiwane: [0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# AND\n",
    "model_and = SigmoidNeuron(2, learning_rate=0.1)\n",
    "model_and.train(AND_inputs, AND_labels, epochs=1000)\n",
    "\n",
    "print(f\"Wagi: {model_and.weights}\")\n",
    "print(f\"Bias: {model_and.bias}\")\n",
    "print(f\"Predykcje: {model_and.feedforward(AND_inputs)}\")\n",
    "print(f\"Wartości oczekiwane: {AND_labels}\\n\")\n",
    "\n",
    "# OR\n",
    "model_or = SigmoidNeuron(2, learning_rate=0.1)\n",
    "model_or.train(OR_inputs, OR_labels, epochs=1000)\n",
    "\n",
    "print(f\"Wagi: {model_or.weights}\")\n",
    "print(f\"Bias: {model_or.bias}\")\n",
    "print(f\"Predykcje: {model_or.feedforward(OR_inputs)}\")\n",
    "print(f\"Wartości oczekiwane: {OR_labels}\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:03.150444200Z",
     "start_time": "2024-03-20T10:53:02.872043Z"
    }
   },
   "id": "f91cce12ec58ff6c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Różne wartości learning rate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a39dad48dad244a3"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "learning_rates = [0.00001, 0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 3.0, 5.0, 7.0, 9.0, 10.0, 30.0, 50.0, 70.0, 90.0, 100.0, 300.0, 500.0, 700.0, 900.0, 1000.0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:03.196612200Z",
     "start_time": "2024-03-20T10:53:03.151443900Z"
    }
   },
   "id": "f6de133d0df55b8d"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "   gate activation function  learning_rate epochs  \\\n0   AND             sigmoid        0.00001   1000   \n1   AND             sigmoid        0.00010   1000   \n2   AND             sigmoid        0.00100   1000   \n3   AND             sigmoid        0.01000   1000   \n4   AND             sigmoid        0.10000   1000   \n5   AND             sigmoid        0.30000   1000   \n6   AND             sigmoid        0.50000   1000   \n7   AND             sigmoid        0.70000   1000   \n8   AND             sigmoid        0.90000   1000   \n9   AND             sigmoid        1.00000   1000   \n10  AND             sigmoid        3.00000   1000   \n11  AND             sigmoid        5.00000   1000   \n12  AND             sigmoid        7.00000   1000   \n13  AND             sigmoid        9.00000   1000   \n14  AND             sigmoid       10.00000   1000   \n15  AND             sigmoid       30.00000   1000   \n16  AND             sigmoid       50.00000   1000   \n17  AND             sigmoid       70.00000   1000   \n18  AND             sigmoid       90.00000   1000   \n19  AND             sigmoid      100.00000   1000   \n20  AND             sigmoid      300.00000   1000   \n21  AND             sigmoid      500.00000   1000   \n22  AND             sigmoid      700.00000   1000   \n23  AND             sigmoid      900.00000   1000   \n24  AND             sigmoid     1000.00000   1000   \n\n                                         weights                    bias  \\\n0    [0.009737070743234265, 0.04300392884882873]  [0.019506279256317212]   \n1   [0.009531306737583638, 0.042723303690111014]  [0.010137314442084823]   \n2    [0.009803004925988828, 0.04224428305354898]  [-0.07897328470309319]   \n3     [0.14880944862150583, 0.17397840984276913]   [-0.6791856468956367]   \n4       [1.8188862600575684, 1.7977855343202513]   [-2.9408580784034233]   \n5         [3.515449937540129, 3.466281649029582]    [-5.350279654965837]   \n6         [4.489165052643436, 4.434010001743501]    [-6.780774305227138]   \n7         [5.175500994094484, 5.118615919098224]    [-7.799343584666728]   \n8         [5.704148832393772, 5.646848714004917]    [-8.587674800812927]   \n9         [5.928856455940704, 5.871562208446874]    [-8.923516202598599]   \n10         [8.375637269774211, 8.32337480044826]   [-12.599549297708942]   \n11        [9.966753965820269, 9.901007060318083]   [-14.998928686580621]   \n12      [12.812999399553565, 11.562045639730172]   [-18.533738809787174]   \n13      [17.123557832610665, 12.408726501813973]    [-23.19549400953322]   \n14      [19.321694635139508, 12.785566084664215]    [-25.58186201521972]   \n15        [60.00991791561681, 30.04398041518975]     [-75.1334159121066]   \n16       [100.00976272663286, 50.04303795301599]   [-125.23634669434148]   \n17       [140.00976270078817, 70.04303787327996]   [-175.33910648074703]   \n18        [180.00976270078547, 90.0430378732745]   [-225.44186623959678]   \n19       [200.00976270078547, 100.0430378732745]   [-250.49324611902023]   \n20       [600.0097627007855, 300.04303787327444]    [-751.5208437074893]   \n21      [1000.0097627007855, 500.04303787327444]   [-1252.5484412959586]   \n22       [1400.0097627007854, 700.0430378732744]   [-1753.5760388844276]   \n23       [1800.0097627007854, 900.0430378732744]   [-2254.6036364728966]   \n24      [2000.0097627007854, 1000.0430378732744]   [-2505.1174352671314]   \n\n                 predictions      expected                     errors  \n0    [0.5, 0.52, 0.51, 0.52]  [0, 0, 0, 1]   [0.5, 0.52, 0.51, -0.48]  \n1     [0.5, 0.51, 0.5, 0.52]  [0, 0, 0, 1]    [0.5, 0.51, 0.5, -0.48]  \n2   [0.48, 0.49, 0.48, 0.49]  [0, 0, 0, 1]  [0.48, 0.49, 0.48, -0.51]  \n3   [0.34, 0.38, 0.37, 0.41]  [0, 0, 0, 1]  [0.34, 0.38, 0.37, -0.59]  \n4   [0.05, 0.24, 0.25, 0.66]  [0, 0, 0, 1]  [0.05, 0.24, 0.25, -0.34]  \n5    [0.0, 0.13, 0.14, 0.84]  [0, 0, 0, 1]   [0.0, 0.13, 0.14, -0.16]  \n6    [0.0, 0.09, 0.09, 0.89]  [0, 0, 0, 1]   [0.0, 0.09, 0.09, -0.11]  \n7    [0.0, 0.06, 0.07, 0.92]  [0, 0, 0, 1]   [0.0, 0.06, 0.07, -0.08]  \n8    [0.0, 0.05, 0.05, 0.94]  [0, 0, 0, 1]   [0.0, 0.05, 0.05, -0.06]  \n9    [0.0, 0.05, 0.05, 0.95]  [0, 0, 0, 1]   [0.0, 0.05, 0.05, -0.05]  \n10   [0.0, 0.01, 0.01, 0.98]  [0, 0, 0, 1]   [0.0, 0.01, 0.01, -0.02]  \n11   [0.0, 0.01, 0.01, 0.99]  [0, 0, 0, 1]   [0.0, 0.01, 0.01, -0.01]  \n12      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]      [0.0, 0.0, 0.0, -0.0]  \n13      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]      [0.0, 0.0, 0.0, -0.0]  \n14      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]      [0.0, 0.0, 0.0, -0.0]  \n15      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]      [0.0, 0.0, 0.0, -0.0]  \n16      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]      [0.0, 0.0, 0.0, -0.0]  \n17      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]      [0.0, 0.0, 0.0, -0.0]  \n18      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]       [0.0, 0.0, 0.0, 0.0]  \n19      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]       [0.0, 0.0, 0.0, 0.0]  \n20      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]       [0.0, 0.0, 0.0, 0.0]  \n21      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]       [0.0, 0.0, 0.0, 0.0]  \n22      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]       [0.0, 0.0, 0.0, 0.0]  \n23      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]       [0.0, 0.0, 0.0, 0.0]  \n24      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]       [0.0, 0.0, 0.0, 0.0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gate</th>\n      <th>activation function</th>\n      <th>learning_rate</th>\n      <th>epochs</th>\n      <th>weights</th>\n      <th>bias</th>\n      <th>predictions</th>\n      <th>expected</th>\n      <th>errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.00001</td>\n      <td>1000</td>\n      <td>[0.009737070743234265, 0.04300392884882873]</td>\n      <td>[0.019506279256317212]</td>\n      <td>[0.5, 0.52, 0.51, 0.52]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.5, 0.52, 0.51, -0.48]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.00010</td>\n      <td>1000</td>\n      <td>[0.009531306737583638, 0.042723303690111014]</td>\n      <td>[0.010137314442084823]</td>\n      <td>[0.5, 0.51, 0.5, 0.52]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.5, 0.51, 0.5, -0.48]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.00100</td>\n      <td>1000</td>\n      <td>[0.009803004925988828, 0.04224428305354898]</td>\n      <td>[-0.07897328470309319]</td>\n      <td>[0.48, 0.49, 0.48, 0.49]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.48, 0.49, 0.48, -0.51]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.01000</td>\n      <td>1000</td>\n      <td>[0.14880944862150583, 0.17397840984276913]</td>\n      <td>[-0.6791856468956367]</td>\n      <td>[0.34, 0.38, 0.37, 0.41]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.34, 0.38, 0.37, -0.59]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.10000</td>\n      <td>1000</td>\n      <td>[1.8188862600575684, 1.7977855343202513]</td>\n      <td>[-2.9408580784034233]</td>\n      <td>[0.05, 0.24, 0.25, 0.66]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.05, 0.24, 0.25, -0.34]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.30000</td>\n      <td>1000</td>\n      <td>[3.515449937540129, 3.466281649029582]</td>\n      <td>[-5.350279654965837]</td>\n      <td>[0.0, 0.13, 0.14, 0.84]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.13, 0.14, -0.16]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.50000</td>\n      <td>1000</td>\n      <td>[4.489165052643436, 4.434010001743501]</td>\n      <td>[-6.780774305227138]</td>\n      <td>[0.0, 0.09, 0.09, 0.89]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.09, 0.09, -0.11]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.70000</td>\n      <td>1000</td>\n      <td>[5.175500994094484, 5.118615919098224]</td>\n      <td>[-7.799343584666728]</td>\n      <td>[0.0, 0.06, 0.07, 0.92]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.06, 0.07, -0.08]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.90000</td>\n      <td>1000</td>\n      <td>[5.704148832393772, 5.646848714004917]</td>\n      <td>[-8.587674800812927]</td>\n      <td>[0.0, 0.05, 0.05, 0.94]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.05, 0.05, -0.06]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>1.00000</td>\n      <td>1000</td>\n      <td>[5.928856455940704, 5.871562208446874]</td>\n      <td>[-8.923516202598599]</td>\n      <td>[0.0, 0.05, 0.05, 0.95]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.05, 0.05, -0.05]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>3.00000</td>\n      <td>1000</td>\n      <td>[8.375637269774211, 8.32337480044826]</td>\n      <td>[-12.599549297708942]</td>\n      <td>[0.0, 0.01, 0.01, 0.98]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.01, 0.01, -0.02]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>5.00000</td>\n      <td>1000</td>\n      <td>[9.966753965820269, 9.901007060318083]</td>\n      <td>[-14.998928686580621]</td>\n      <td>[0.0, 0.01, 0.01, 0.99]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.01, 0.01, -0.01]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>7.00000</td>\n      <td>1000</td>\n      <td>[12.812999399553565, 11.562045639730172]</td>\n      <td>[-18.533738809787174]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>9.00000</td>\n      <td>1000</td>\n      <td>[17.123557832610665, 12.408726501813973]</td>\n      <td>[-23.19549400953322]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>10.00000</td>\n      <td>1000</td>\n      <td>[19.321694635139508, 12.785566084664215]</td>\n      <td>[-25.58186201521972]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>30.00000</td>\n      <td>1000</td>\n      <td>[60.00991791561681, 30.04398041518975]</td>\n      <td>[-75.1334159121066]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>50.00000</td>\n      <td>1000</td>\n      <td>[100.00976272663286, 50.04303795301599]</td>\n      <td>[-125.23634669434148]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>70.00000</td>\n      <td>1000</td>\n      <td>[140.00976270078817, 70.04303787327996]</td>\n      <td>[-175.33910648074703]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>90.00000</td>\n      <td>1000</td>\n      <td>[180.00976270078547, 90.0430378732745]</td>\n      <td>[-225.44186623959678]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>100.00000</td>\n      <td>1000</td>\n      <td>[200.00976270078547, 100.0430378732745]</td>\n      <td>[-250.49324611902023]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>300.00000</td>\n      <td>1000</td>\n      <td>[600.0097627007855, 300.04303787327444]</td>\n      <td>[-751.5208437074893]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>500.00000</td>\n      <td>1000</td>\n      <td>[1000.0097627007855, 500.04303787327444]</td>\n      <td>[-1252.5484412959586]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>700.00000</td>\n      <td>1000</td>\n      <td>[1400.0097627007854, 700.0430378732744]</td>\n      <td>[-1753.5760388844276]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>900.00000</td>\n      <td>1000</td>\n      <td>[1800.0097627007854, 900.0430378732744]</td>\n      <td>[-2254.6036364728966]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>1000.00000</td>\n      <td>1000</td>\n      <td>[2000.0097627007854, 1000.0430378732744]</td>\n      <td>[-2505.1174352671314]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AND\n",
    "df_lr_and = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model_and = SigmoidNeuron(2, learning_rate=lr)\n",
    "    model_and.train(AND_inputs, AND_labels, epochs=100)\n",
    "    df_lr_and = df_lr_and._append({'gate': 'AND', 'activation function': sigmoid.__name__, 'learning_rate': lr, 'epochs': 1000, 'weights': model_and.weights, 'bias': model_and.bias, 'predictions': np.round(model_and.feedforward(AND_inputs), 2), 'expected': AND_labels, 'errors': np.round(model_and.feedforward(AND_inputs) - AND_labels, 2)}, ignore_index=True)\n",
    "    \n",
    "df_lr_and"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:03.549889100Z",
     "start_time": "2024-03-20T10:53:03.168255200Z"
    }
   },
   "id": "7879d2cbc01b568a"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "   gate activation function  learning_rate epochs  \\\n0    OR             sigmoid        0.00001   1000   \n1    OR             sigmoid        0.00010   1000   \n2    OR             sigmoid        0.00100   1000   \n3    OR             sigmoid        0.01000   1000   \n4    OR             sigmoid        0.10000   1000   \n5    OR             sigmoid        0.30000   1000   \n6    OR             sigmoid        0.50000   1000   \n7    OR             sigmoid        0.70000   1000   \n8    OR             sigmoid        0.90000   1000   \n9    OR             sigmoid        1.00000   1000   \n10   OR             sigmoid        3.00000   1000   \n11   OR             sigmoid        5.00000   1000   \n12   OR             sigmoid        7.00000   1000   \n13   OR             sigmoid        9.00000   1000   \n14   OR             sigmoid       10.00000   1000   \n15   OR             sigmoid       30.00000   1000   \n16   OR             sigmoid       50.00000   1000   \n17   OR             sigmoid       70.00000   1000   \n18   OR             sigmoid       90.00000   1000   \n19   OR             sigmoid      100.00000   1000   \n20   OR             sigmoid      300.00000   1000   \n21   OR             sigmoid      500.00000   1000   \n22   OR             sigmoid      700.00000   1000   \n23   OR             sigmoid      900.00000   1000   \n24   OR             sigmoid     1000.00000   1000   \n\n                                         weights                    bias  \\\n0      [0.0107361932374163, 0.04400305413243955]  [0.021504783722504917]   \n1   [0.019443987547883016, 0.052636263627169756]  [0.029988480462205914]   \n2     [0.10149743819530734, 0.13396662073353405]   [0.10684991126297322]   \n3       [0.6276554067284316, 0.6549890518403566]   [0.41022906302968604]   \n4        [2.507140927039107, 2.5282442628704165]   [-0.5778533936024522]   \n5           [4.39339482000521, 4.42344328184911]   [-1.6588114138881587]   \n6         [5.420125566852021, 5.454089760500101]    [-2.200454279163118]   \n7         [6.118429909495018, 6.154153937975927]   [-2.5614842675798806]   \n8         [6.645494792573381, 6.682130245915327]   [-2.8315141819668845]   \n9          [6.867245925383133, 6.90417313654303]   [-2.9446435612960706]   \n10        [9.189444699918825, 9.227131250273386]    [-4.119080969171553]   \n11      [10.285976535832097, 10.322753654530242]    [-4.670134835452762]   \n12      [11.088317047047306, 11.121339787483832]    [-5.072690573429941]   \n13      [11.866010888290223, 11.892408364612557]    [-5.463078643186184]   \n14      [12.304405419623285, 12.327284891114404]    [-5.683521665628401]   \n15      [30.010781720677997, 30.044023030143357]   [-15.132341167982528]   \n16          [50.00976278645991, 50.043037956108]    [-25.23634660481457]   \n17        [70.00976270079107, 70.04303787328008]     [-35.3391064807399]   \n18        [90.00976270078546, 90.04303787327449]    [-45.44186623959677]   \n19      [100.00976270078546, 100.04303787327449]    [-50.49324611902023]   \n20        [300.0097627007855, 300.0430378732745]   [-151.52084370748932]   \n21        [500.0097627007855, 500.0430378732745]   [-252.54844129595844]   \n22        [700.0097627007855, 700.0430378732744]   [-353.57603888442753]   \n23        [900.0097627007855, 900.0430378732744]   [-454.60363647289665]   \n24      [1000.0097627007855, 1000.0430378732744]    [-505.1174352671312]   \n\n                 predictions      expected                       errors  \n0   [0.51, 0.52, 0.51, 0.52]  [0, 1, 1, 1]  [0.51, -0.48, -0.49, -0.48]  \n1   [0.51, 0.52, 0.51, 0.53]  [0, 1, 1, 1]  [0.51, -0.48, -0.49, -0.47]  \n2   [0.53, 0.56, 0.55, 0.58]  [0, 1, 1, 1]  [0.53, -0.44, -0.45, -0.42]  \n3    [0.6, 0.74, 0.74, 0.84]  [0, 1, 1, 1]   [0.6, -0.26, -0.26, -0.16]  \n4   [0.36, 0.88, 0.87, 0.99]  [0, 1, 1, 1]  [0.36, -0.12, -0.13, -0.01]  \n5    [0.16, 0.94, 0.94, 1.0]  [0, 1, 1, 1]   [0.16, -0.06, -0.06, -0.0]  \n6     [0.1, 0.96, 0.96, 1.0]  [0, 1, 1, 1]    [0.1, -0.04, -0.04, -0.0]  \n7    [0.07, 0.97, 0.97, 1.0]  [0, 1, 1, 1]   [0.07, -0.03, -0.03, -0.0]  \n8    [0.06, 0.98, 0.98, 1.0]  [0, 1, 1, 1]   [0.06, -0.02, -0.02, -0.0]  \n9    [0.05, 0.98, 0.98, 1.0]  [0, 1, 1, 1]   [0.05, -0.02, -0.02, -0.0]  \n10   [0.02, 0.99, 0.99, 1.0]  [0, 1, 1, 1]   [0.02, -0.01, -0.01, -0.0]  \n11     [0.01, 1.0, 1.0, 1.0]  [0, 1, 1, 1]     [0.01, -0.0, -0.0, -0.0]  \n12     [0.01, 1.0, 1.0, 1.0]  [0, 1, 1, 1]     [0.01, -0.0, -0.0, -0.0]  \n13      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]      [0.0, -0.0, -0.0, -0.0]  \n14      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]      [0.0, -0.0, -0.0, -0.0]  \n15      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]       [0.0, -0.0, -0.0, 0.0]  \n16      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]       [0.0, -0.0, -0.0, 0.0]  \n17      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]       [0.0, -0.0, -0.0, 0.0]  \n18      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]         [0.0, 0.0, 0.0, 0.0]  \n19      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]         [0.0, 0.0, 0.0, 0.0]  \n20      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]         [0.0, 0.0, 0.0, 0.0]  \n21      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]         [0.0, 0.0, 0.0, 0.0]  \n22      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]         [0.0, 0.0, 0.0, 0.0]  \n23      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]         [0.0, 0.0, 0.0, 0.0]  \n24      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]         [0.0, 0.0, 0.0, 0.0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gate</th>\n      <th>activation function</th>\n      <th>learning_rate</th>\n      <th>epochs</th>\n      <th>weights</th>\n      <th>bias</th>\n      <th>predictions</th>\n      <th>expected</th>\n      <th>errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.00001</td>\n      <td>1000</td>\n      <td>[0.0107361932374163, 0.04400305413243955]</td>\n      <td>[0.021504783722504917]</td>\n      <td>[0.51, 0.52, 0.51, 0.52]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.51, -0.48, -0.49, -0.48]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.00010</td>\n      <td>1000</td>\n      <td>[0.019443987547883016, 0.052636263627169756]</td>\n      <td>[0.029988480462205914]</td>\n      <td>[0.51, 0.52, 0.51, 0.53]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.51, -0.48, -0.49, -0.47]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.00100</td>\n      <td>1000</td>\n      <td>[0.10149743819530734, 0.13396662073353405]</td>\n      <td>[0.10684991126297322]</td>\n      <td>[0.53, 0.56, 0.55, 0.58]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.53, -0.44, -0.45, -0.42]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.01000</td>\n      <td>1000</td>\n      <td>[0.6276554067284316, 0.6549890518403566]</td>\n      <td>[0.41022906302968604]</td>\n      <td>[0.6, 0.74, 0.74, 0.84]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.6, -0.26, -0.26, -0.16]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.10000</td>\n      <td>1000</td>\n      <td>[2.507140927039107, 2.5282442628704165]</td>\n      <td>[-0.5778533936024522]</td>\n      <td>[0.36, 0.88, 0.87, 0.99]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.36, -0.12, -0.13, -0.01]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.30000</td>\n      <td>1000</td>\n      <td>[4.39339482000521, 4.42344328184911]</td>\n      <td>[-1.6588114138881587]</td>\n      <td>[0.16, 0.94, 0.94, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.16, -0.06, -0.06, -0.0]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.50000</td>\n      <td>1000</td>\n      <td>[5.420125566852021, 5.454089760500101]</td>\n      <td>[-2.200454279163118]</td>\n      <td>[0.1, 0.96, 0.96, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.1, -0.04, -0.04, -0.0]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.70000</td>\n      <td>1000</td>\n      <td>[6.118429909495018, 6.154153937975927]</td>\n      <td>[-2.5614842675798806]</td>\n      <td>[0.07, 0.97, 0.97, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.07, -0.03, -0.03, -0.0]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.90000</td>\n      <td>1000</td>\n      <td>[6.645494792573381, 6.682130245915327]</td>\n      <td>[-2.8315141819668845]</td>\n      <td>[0.06, 0.98, 0.98, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.06, -0.02, -0.02, -0.0]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>1.00000</td>\n      <td>1000</td>\n      <td>[6.867245925383133, 6.90417313654303]</td>\n      <td>[-2.9446435612960706]</td>\n      <td>[0.05, 0.98, 0.98, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.05, -0.02, -0.02, -0.0]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>3.00000</td>\n      <td>1000</td>\n      <td>[9.189444699918825, 9.227131250273386]</td>\n      <td>[-4.119080969171553]</td>\n      <td>[0.02, 0.99, 0.99, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.02, -0.01, -0.01, -0.0]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>5.00000</td>\n      <td>1000</td>\n      <td>[10.285976535832097, 10.322753654530242]</td>\n      <td>[-4.670134835452762]</td>\n      <td>[0.01, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.01, -0.0, -0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>7.00000</td>\n      <td>1000</td>\n      <td>[11.088317047047306, 11.121339787483832]</td>\n      <td>[-5.072690573429941]</td>\n      <td>[0.01, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.01, -0.0, -0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>9.00000</td>\n      <td>1000</td>\n      <td>[11.866010888290223, 11.892408364612557]</td>\n      <td>[-5.463078643186184]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, -0.0, -0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>10.00000</td>\n      <td>1000</td>\n      <td>[12.304405419623285, 12.327284891114404]</td>\n      <td>[-5.683521665628401]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, -0.0, -0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>30.00000</td>\n      <td>1000</td>\n      <td>[30.010781720677997, 30.044023030143357]</td>\n      <td>[-15.132341167982528]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, -0.0, -0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>50.00000</td>\n      <td>1000</td>\n      <td>[50.00976278645991, 50.043037956108]</td>\n      <td>[-25.23634660481457]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, -0.0, -0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>70.00000</td>\n      <td>1000</td>\n      <td>[70.00976270079107, 70.04303787328008]</td>\n      <td>[-35.3391064807399]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, -0.0, -0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>90.00000</td>\n      <td>1000</td>\n      <td>[90.00976270078546, 90.04303787327449]</td>\n      <td>[-45.44186623959677]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>100.00000</td>\n      <td>1000</td>\n      <td>[100.00976270078546, 100.04303787327449]</td>\n      <td>[-50.49324611902023]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>300.00000</td>\n      <td>1000</td>\n      <td>[300.0097627007855, 300.0430378732745]</td>\n      <td>[-151.52084370748932]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>500.00000</td>\n      <td>1000</td>\n      <td>[500.0097627007855, 500.0430378732745]</td>\n      <td>[-252.54844129595844]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>700.00000</td>\n      <td>1000</td>\n      <td>[700.0097627007855, 700.0430378732744]</td>\n      <td>[-353.57603888442753]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>900.00000</td>\n      <td>1000</td>\n      <td>[900.0097627007855, 900.0430378732744]</td>\n      <td>[-454.60363647289665]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>1000.00000</td>\n      <td>1000</td>\n      <td>[1000.0097627007855, 1000.0430378732744]</td>\n      <td>[-505.1174352671312]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR\n",
    "df_lr_or = pd.DataFrame(columns=columns)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model_or = SigmoidNeuron(2, learning_rate=lr)\n",
    "    model_or.train(OR_inputs, OR_labels, epochs=100)\n",
    "    df_lr_or = df_lr_or._append({'gate': 'OR', 'activation function': sigmoid.__name__, 'learning_rate': lr, 'epochs': 1000, 'weights': model_or.weights, 'bias': model_or.bias, 'predictions': np.round(model_or.feedforward(OR_inputs), 2), 'expected': OR_labels, 'errors': np.round(model_or.feedforward(OR_inputs) - OR_labels, 2)}, ignore_index=True)\n",
    "    \n",
    "df_lr_or"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:03.929624800Z",
     "start_time": "2024-03-20T10:53:03.542868200Z"
    }
   },
   "id": "4b4c699fd3a0e818"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Różne ilości epok"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d14dee5b4c161892"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "epochs = [1, 2, 3, 4, 5, 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 1000, 2000, 3000, 4000, 5000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:03.956005Z",
     "start_time": "2024-03-20T10:53:03.930623600Z"
    }
   },
   "id": "d52f08ced60c48ca"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "   gate activation function  learning_rate epochs  \\\n0   AND             sigmoid            0.3      1   \n1   AND             sigmoid            0.3      2   \n2   AND             sigmoid            0.3      3   \n3   AND             sigmoid            0.3      4   \n4   AND             sigmoid            0.3      5   \n5   AND             sigmoid            0.3     10   \n6   AND             sigmoid            0.3     20   \n7   AND             sigmoid            0.3     30   \n8   AND             sigmoid            0.3     40   \n9   AND             sigmoid            0.3     50   \n10  AND             sigmoid            0.3    100   \n11  AND             sigmoid            0.3    200   \n12  AND             sigmoid            0.3    300   \n13  AND             sigmoid            0.3    400   \n14  AND             sigmoid            0.3    500   \n15  AND             sigmoid            0.3   1000   \n16  AND             sigmoid            0.3   2000   \n17  AND             sigmoid            0.3   3000   \n18  AND             sigmoid            0.3   4000   \n19  AND             sigmoid            0.3   5000   \n\n                                       weights                    bias  \\\n0      [0.074938399215815, 0.0950731132379126]  [-0.20922095792653186]   \n1    [0.1534903736036208, 0.16255439372509362]   [-0.3964912425767355]   \n2   [0.23823868505762305, 0.23777819357118624]   [-0.5560710354927241]   \n3    [0.32502700216804586, 0.3162261279138247]   [-0.6970275539066508]   \n4    [0.4114339591937235, 0.39523572322067424]   [-0.8249992533551076]   \n5      [0.806809020372371, 0.7634570750444343]   [-1.3587618054860977]   \n6     [1.4032199598801471, 1.3345344303481284]    [-2.175016819184286]   \n7       [1.8401708690075322, 1.76501075902905]   [-2.8071339073674966]   \n8     [2.1887232337610083, 2.1146384896516666]   [-3.3261957974630225]   \n9     [2.4814314811925224, 2.4111908679818472]   [-3.7685890915123754]   \n10      [3.515449937540129, 3.466281649029582]    [-5.350279654965837]   \n11      [4.715831992891851, 4.687242414869826]      [-7.1863770792978]   \n12      [5.472604222470841, 5.452697613549096]    [-8.337713212515842]   \n13      [6.025370080328531, 6.010150231634654]    [-9.175865132818219]   \n14       [6.460475623715049, 6.44817357737694]     [-9.83421980724841]   \n15      [7.833260266400745, 7.827009109782254]   [-11.905421979318573]   \n16      [9.220700712111306, 9.217562293440546]   [-13.992874597205143]   \n17    [10.034297166371283, 10.032204434990659]   [-15.215398371023898]   \n18    [10.611704486010838, 10.610135329143347]   [-16.082578227106776]   \n19     [11.059529756592532, 11.05827481634788]   [-16.754958508161458]   \n\n                 predictions      expected                     errors  \n0   [0.45, 0.47, 0.47, 0.49]  [0, 0, 0, 1]  [0.45, 0.47, 0.47, -0.51]  \n1    [0.4, 0.44, 0.44, 0.48]  [0, 0, 0, 1]   [0.4, 0.44, 0.44, -0.52]  \n2   [0.36, 0.42, 0.42, 0.48]  [0, 0, 0, 1]  [0.36, 0.42, 0.42, -0.52]  \n3   [0.33, 0.41, 0.41, 0.49]  [0, 0, 0, 1]  [0.33, 0.41, 0.41, -0.51]  \n4      [0.3, 0.39, 0.4, 0.5]  [0, 0, 0, 1]     [0.3, 0.39, 0.4, -0.5]  \n5    [0.2, 0.36, 0.37, 0.55]  [0, 0, 0, 1]   [0.2, 0.36, 0.37, -0.45]  \n6     [0.1, 0.3, 0.32, 0.64]  [0, 0, 0, 1]    [0.1, 0.3, 0.32, -0.36]  \n7   [0.06, 0.26, 0.28, 0.69]  [0, 0, 0, 1]  [0.06, 0.26, 0.28, -0.31]  \n8   [0.03, 0.23, 0.24, 0.73]  [0, 0, 0, 1]  [0.03, 0.23, 0.24, -0.27]  \n9    [0.02, 0.2, 0.22, 0.75]  [0, 0, 0, 1]   [0.02, 0.2, 0.22, -0.25]  \n10   [0.0, 0.13, 0.14, 0.84]  [0, 0, 0, 1]   [0.0, 0.13, 0.14, -0.16]  \n11    [0.0, 0.08, 0.08, 0.9]  [0, 0, 0, 1]    [0.0, 0.08, 0.08, -0.1]  \n12   [0.0, 0.05, 0.05, 0.93]  [0, 0, 0, 1]   [0.0, 0.05, 0.05, -0.07]  \n13   [0.0, 0.04, 0.04, 0.95]  [0, 0, 0, 1]   [0.0, 0.04, 0.04, -0.05]  \n14   [0.0, 0.03, 0.03, 0.96]  [0, 0, 0, 1]   [0.0, 0.03, 0.03, -0.04]  \n15   [0.0, 0.02, 0.02, 0.98]  [0, 0, 0, 1]   [0.0, 0.02, 0.02, -0.02]  \n16   [0.0, 0.01, 0.01, 0.99]  [0, 0, 0, 1]   [0.0, 0.01, 0.01, -0.01]  \n17   [0.0, 0.01, 0.01, 0.99]  [0, 0, 0, 1]   [0.0, 0.01, 0.01, -0.01]  \n18     [0.0, 0.0, 0.0, 0.99]  [0, 0, 0, 1]     [0.0, 0.0, 0.0, -0.01]  \n19      [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]      [0.0, 0.0, 0.0, -0.0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gate</th>\n      <th>activation function</th>\n      <th>learning_rate</th>\n      <th>epochs</th>\n      <th>weights</th>\n      <th>bias</th>\n      <th>predictions</th>\n      <th>expected</th>\n      <th>errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>1</td>\n      <td>[0.074938399215815, 0.0950731132379126]</td>\n      <td>[-0.20922095792653186]</td>\n      <td>[0.45, 0.47, 0.47, 0.49]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.45, 0.47, 0.47, -0.51]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>2</td>\n      <td>[0.1534903736036208, 0.16255439372509362]</td>\n      <td>[-0.3964912425767355]</td>\n      <td>[0.4, 0.44, 0.44, 0.48]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.4, 0.44, 0.44, -0.52]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>3</td>\n      <td>[0.23823868505762305, 0.23777819357118624]</td>\n      <td>[-0.5560710354927241]</td>\n      <td>[0.36, 0.42, 0.42, 0.48]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.36, 0.42, 0.42, -0.52]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>4</td>\n      <td>[0.32502700216804586, 0.3162261279138247]</td>\n      <td>[-0.6970275539066508]</td>\n      <td>[0.33, 0.41, 0.41, 0.49]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.33, 0.41, 0.41, -0.51]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>5</td>\n      <td>[0.4114339591937235, 0.39523572322067424]</td>\n      <td>[-0.8249992533551076]</td>\n      <td>[0.3, 0.39, 0.4, 0.5]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.3, 0.39, 0.4, -0.5]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>10</td>\n      <td>[0.806809020372371, 0.7634570750444343]</td>\n      <td>[-1.3587618054860977]</td>\n      <td>[0.2, 0.36, 0.37, 0.55]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.2, 0.36, 0.37, -0.45]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>20</td>\n      <td>[1.4032199598801471, 1.3345344303481284]</td>\n      <td>[-2.175016819184286]</td>\n      <td>[0.1, 0.3, 0.32, 0.64]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.1, 0.3, 0.32, -0.36]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>30</td>\n      <td>[1.8401708690075322, 1.76501075902905]</td>\n      <td>[-2.8071339073674966]</td>\n      <td>[0.06, 0.26, 0.28, 0.69]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.06, 0.26, 0.28, -0.31]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>40</td>\n      <td>[2.1887232337610083, 2.1146384896516666]</td>\n      <td>[-3.3261957974630225]</td>\n      <td>[0.03, 0.23, 0.24, 0.73]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.03, 0.23, 0.24, -0.27]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>50</td>\n      <td>[2.4814314811925224, 2.4111908679818472]</td>\n      <td>[-3.7685890915123754]</td>\n      <td>[0.02, 0.2, 0.22, 0.75]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.02, 0.2, 0.22, -0.25]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>100</td>\n      <td>[3.515449937540129, 3.466281649029582]</td>\n      <td>[-5.350279654965837]</td>\n      <td>[0.0, 0.13, 0.14, 0.84]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.13, 0.14, -0.16]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>200</td>\n      <td>[4.715831992891851, 4.687242414869826]</td>\n      <td>[-7.1863770792978]</td>\n      <td>[0.0, 0.08, 0.08, 0.9]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.08, 0.08, -0.1]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>300</td>\n      <td>[5.472604222470841, 5.452697613549096]</td>\n      <td>[-8.337713212515842]</td>\n      <td>[0.0, 0.05, 0.05, 0.93]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.05, 0.05, -0.07]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>400</td>\n      <td>[6.025370080328531, 6.010150231634654]</td>\n      <td>[-9.175865132818219]</td>\n      <td>[0.0, 0.04, 0.04, 0.95]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.04, 0.04, -0.05]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>500</td>\n      <td>[6.460475623715049, 6.44817357737694]</td>\n      <td>[-9.83421980724841]</td>\n      <td>[0.0, 0.03, 0.03, 0.96]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.03, 0.03, -0.04]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>1000</td>\n      <td>[7.833260266400745, 7.827009109782254]</td>\n      <td>[-11.905421979318573]</td>\n      <td>[0.0, 0.02, 0.02, 0.98]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.02, 0.02, -0.02]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>2000</td>\n      <td>[9.220700712111306, 9.217562293440546]</td>\n      <td>[-13.992874597205143]</td>\n      <td>[0.0, 0.01, 0.01, 0.99]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.01, 0.01, -0.01]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>3000</td>\n      <td>[10.034297166371283, 10.032204434990659]</td>\n      <td>[-15.215398371023898]</td>\n      <td>[0.0, 0.01, 0.01, 0.99]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.01, 0.01, -0.01]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>4000</td>\n      <td>[10.611704486010838, 10.610135329143347]</td>\n      <td>[-16.082578227106776]</td>\n      <td>[0.0, 0.0, 0.0, 0.99]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, -0.01]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>5000</td>\n      <td>[11.059529756592532, 11.05827481634788]</td>\n      <td>[-16.754958508161458]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, -0.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AND\n",
    "df_epochs_and = pd.DataFrame(columns=columns)\n",
    "\n",
    "for epoch in epochs:\n",
    "    model_and = SigmoidNeuron(2, learning_rate=0.3)\n",
    "    model_and.train(AND_inputs, AND_labels, epochs=epoch)\n",
    "    df_epochs_and = df_epochs_and._append({'gate': 'AND', 'activation function': sigmoid.__name__, 'learning_rate': 0.3, 'epochs': epoch, 'weights': model_and.weights, 'bias': model_and.bias, 'predictions': np.round(model_and.feedforward(AND_inputs), 2), 'expected': AND_labels, 'errors': np.round(model_and.feedforward(AND_inputs) - AND_labels, 2)}, ignore_index=True)\n",
    "    \n",
    "df_epochs_and"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:06.048376Z",
     "start_time": "2024-03-20T10:53:03.947064400Z"
    }
   },
   "id": "a16b7565e5f8873"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "   gate activation function  learning_rate epochs  \\\n0    OR             sigmoid            0.3      1   \n1    OR             sigmoid            0.3      2   \n2    OR             sigmoid            0.3      3   \n3    OR             sigmoid            0.3      4   \n4    OR             sigmoid            0.3      5   \n5    OR             sigmoid            0.3     10   \n6    OR             sigmoid            0.3     20   \n7    OR             sigmoid            0.3     30   \n8    OR             sigmoid            0.3     40   \n9    OR             sigmoid            0.3     50   \n10   OR             sigmoid            0.3    100   \n11   OR             sigmoid            0.3    200   \n12   OR             sigmoid            0.3    300   \n13   OR             sigmoid            0.3    400   \n14   OR             sigmoid            0.3    500   \n15   OR             sigmoid            0.3   1000   \n16   OR             sigmoid            0.3   2000   \n17   OR             sigmoid            0.3   3000   \n18   OR             sigmoid            0.3   4000   \n19   OR             sigmoid            0.3   5000   \n\n                                      weights                    bias  \\\n0    [0.2682871679667611, 0.3108065821694219]   [0.28412781082441424]   \n1   [0.45337491980295896, 0.5013120675693208]    [0.4167328932039728]   \n2     [0.598815107259879, 0.6499510702742095]   [0.47844546858133036]   \n3    [0.7208253718268421, 0.7739402500755562]    [0.4993189079706561]   \n4    [0.8277439664378151, 0.8821285811924395]   [0.49522717598892957]   \n5    [1.2500538881181296, 1.3064509686802837]   [0.32295955043782015]   \n6    [1.8788091223718002, 1.9335526845852207]  [-0.11767100316816659]   \n7     [2.377895665357119, 2.4292523277416946]  [-0.46577260986554864]   \n8     [2.793950944526616, 2.8415133107432093]    [-0.735283556226876]   \n9     [3.149177137887739, 3.1930292470869186]   [-0.9528755191775193]   \n10       [4.39339482000521, 4.42344328184911]   [-1.6588114138881587]   \n11     [5.762893088554891, 5.780547386185774]    [-2.385178526433645]   \n12    [6.5871397454297655, 6.599510482636379]    [-2.810633603095611]   \n13     [7.175269292455186, 7.184764687665445]   [-3.1111833949033447]   \n14     [7.631902842930237, 7.639599087720676]   [-3.3433175442113643]   \n15     [9.047619812713735, 9.051559097189308]    [-4.058605842307561]   \n16   [10.455682681736455, 10.457671225644996]    [-4.766224885923234]   \n17   [11.275793499170435, 11.277122678376875]    [-5.177452454206905]   \n18   [11.856334529323862, 11.857332559532324]    [-5.468303880799152]   \n19    [12.305984143197382, 12.30678306231252]    [-5.693475435504954]   \n\n                 predictions      expected                       errors  \n0    [0.57, 0.64, 0.63, 0.7]  [0, 1, 1, 1]   [0.57, -0.36, -0.37, -0.3]  \n1      [0.6, 0.71, 0.7, 0.8]  [0, 1, 1, 1]     [0.6, -0.29, -0.3, -0.2]  \n2   [0.62, 0.76, 0.75, 0.85]  [0, 1, 1, 1]  [0.62, -0.24, -0.25, -0.15]  \n3   [0.62, 0.78, 0.77, 0.88]  [0, 1, 1, 1]  [0.62, -0.22, -0.23, -0.12]  \n4     [0.62, 0.8, 0.79, 0.9]  [0, 1, 1, 1]    [0.62, -0.2, -0.21, -0.1]  \n5   [0.58, 0.84, 0.83, 0.95]  [0, 1, 1, 1]  [0.58, -0.16, -0.17, -0.05]  \n6   [0.47, 0.86, 0.85, 0.98]  [0, 1, 1, 1]  [0.47, -0.14, -0.15, -0.02]  \n7   [0.39, 0.88, 0.87, 0.99]  [0, 1, 1, 1]  [0.39, -0.12, -0.13, -0.01]  \n8   [0.32, 0.89, 0.89, 0.99]  [0, 1, 1, 1]  [0.32, -0.11, -0.11, -0.01]  \n9      [0.28, 0.9, 0.9, 1.0]  [0, 1, 1, 1]     [0.28, -0.1, -0.1, -0.0]  \n10   [0.16, 0.94, 0.94, 1.0]  [0, 1, 1, 1]   [0.16, -0.06, -0.06, -0.0]  \n11   [0.08, 0.97, 0.97, 1.0]  [0, 1, 1, 1]   [0.08, -0.03, -0.03, -0.0]  \n12   [0.06, 0.98, 0.98, 1.0]  [0, 1, 1, 1]   [0.06, -0.02, -0.02, -0.0]  \n13   [0.04, 0.98, 0.98, 1.0]  [0, 1, 1, 1]   [0.04, -0.02, -0.02, -0.0]  \n14   [0.03, 0.99, 0.99, 1.0]  [0, 1, 1, 1]   [0.03, -0.01, -0.01, -0.0]  \n15   [0.02, 0.99, 0.99, 1.0]  [0, 1, 1, 1]   [0.02, -0.01, -0.01, -0.0]  \n16     [0.01, 1.0, 1.0, 1.0]  [0, 1, 1, 1]     [0.01, -0.0, -0.0, -0.0]  \n17     [0.01, 1.0, 1.0, 1.0]  [0, 1, 1, 1]     [0.01, -0.0, -0.0, -0.0]  \n18      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]      [0.0, -0.0, -0.0, -0.0]  \n19      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]      [0.0, -0.0, -0.0, -0.0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gate</th>\n      <th>activation function</th>\n      <th>learning_rate</th>\n      <th>epochs</th>\n      <th>weights</th>\n      <th>bias</th>\n      <th>predictions</th>\n      <th>expected</th>\n      <th>errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>1</td>\n      <td>[0.2682871679667611, 0.3108065821694219]</td>\n      <td>[0.28412781082441424]</td>\n      <td>[0.57, 0.64, 0.63, 0.7]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.57, -0.36, -0.37, -0.3]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>2</td>\n      <td>[0.45337491980295896, 0.5013120675693208]</td>\n      <td>[0.4167328932039728]</td>\n      <td>[0.6, 0.71, 0.7, 0.8]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.6, -0.29, -0.3, -0.2]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>3</td>\n      <td>[0.598815107259879, 0.6499510702742095]</td>\n      <td>[0.47844546858133036]</td>\n      <td>[0.62, 0.76, 0.75, 0.85]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.62, -0.24, -0.25, -0.15]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>4</td>\n      <td>[0.7208253718268421, 0.7739402500755562]</td>\n      <td>[0.4993189079706561]</td>\n      <td>[0.62, 0.78, 0.77, 0.88]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.62, -0.22, -0.23, -0.12]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>5</td>\n      <td>[0.8277439664378151, 0.8821285811924395]</td>\n      <td>[0.49522717598892957]</td>\n      <td>[0.62, 0.8, 0.79, 0.9]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.62, -0.2, -0.21, -0.1]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>10</td>\n      <td>[1.2500538881181296, 1.3064509686802837]</td>\n      <td>[0.32295955043782015]</td>\n      <td>[0.58, 0.84, 0.83, 0.95]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.58, -0.16, -0.17, -0.05]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>20</td>\n      <td>[1.8788091223718002, 1.9335526845852207]</td>\n      <td>[-0.11767100316816659]</td>\n      <td>[0.47, 0.86, 0.85, 0.98]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.47, -0.14, -0.15, -0.02]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>30</td>\n      <td>[2.377895665357119, 2.4292523277416946]</td>\n      <td>[-0.46577260986554864]</td>\n      <td>[0.39, 0.88, 0.87, 0.99]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.39, -0.12, -0.13, -0.01]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>40</td>\n      <td>[2.793950944526616, 2.8415133107432093]</td>\n      <td>[-0.735283556226876]</td>\n      <td>[0.32, 0.89, 0.89, 0.99]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.32, -0.11, -0.11, -0.01]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>50</td>\n      <td>[3.149177137887739, 3.1930292470869186]</td>\n      <td>[-0.9528755191775193]</td>\n      <td>[0.28, 0.9, 0.9, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.28, -0.1, -0.1, -0.0]</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>100</td>\n      <td>[4.39339482000521, 4.42344328184911]</td>\n      <td>[-1.6588114138881587]</td>\n      <td>[0.16, 0.94, 0.94, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.16, -0.06, -0.06, -0.0]</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>200</td>\n      <td>[5.762893088554891, 5.780547386185774]</td>\n      <td>[-2.385178526433645]</td>\n      <td>[0.08, 0.97, 0.97, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.08, -0.03, -0.03, -0.0]</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>300</td>\n      <td>[6.5871397454297655, 6.599510482636379]</td>\n      <td>[-2.810633603095611]</td>\n      <td>[0.06, 0.98, 0.98, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.06, -0.02, -0.02, -0.0]</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>400</td>\n      <td>[7.175269292455186, 7.184764687665445]</td>\n      <td>[-3.1111833949033447]</td>\n      <td>[0.04, 0.98, 0.98, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.04, -0.02, -0.02, -0.0]</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>500</td>\n      <td>[7.631902842930237, 7.639599087720676]</td>\n      <td>[-3.3433175442113643]</td>\n      <td>[0.03, 0.99, 0.99, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.03, -0.01, -0.01, -0.0]</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>1000</td>\n      <td>[9.047619812713735, 9.051559097189308]</td>\n      <td>[-4.058605842307561]</td>\n      <td>[0.02, 0.99, 0.99, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.02, -0.01, -0.01, -0.0]</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>2000</td>\n      <td>[10.455682681736455, 10.457671225644996]</td>\n      <td>[-4.766224885923234]</td>\n      <td>[0.01, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.01, -0.0, -0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>3000</td>\n      <td>[11.275793499170435, 11.277122678376875]</td>\n      <td>[-5.177452454206905]</td>\n      <td>[0.01, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.01, -0.0, -0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>4000</td>\n      <td>[11.856334529323862, 11.857332559532324]</td>\n      <td>[-5.468303880799152]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, -0.0, -0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>5000</td>\n      <td>[12.305984143197382, 12.30678306231252]</td>\n      <td>[-5.693475435504954]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, -0.0, -0.0, -0.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR\n",
    "df_epochs_or = pd.DataFrame(columns=columns)\n",
    "\n",
    "for epoch in epochs:\n",
    "    model_or = SigmoidNeuron(2, learning_rate=0.3)\n",
    "    model_or.train(OR_inputs, OR_labels, epochs=epoch)\n",
    "    df_epochs_or = df_epochs_or._append({'gate': 'OR', 'activation function': sigmoid.__name__, 'learning_rate': 0.3, 'epochs': epoch, 'weights': model_or.weights, 'bias': model_or.bias, 'predictions': np.round(model_or.feedforward(OR_inputs), 2), 'expected': OR_labels, 'errors': np.round(model_or.feedforward(OR_inputs) - OR_labels, 2)}, ignore_index=True)\n",
    "    \n",
    "df_epochs_or"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:08.314283900Z",
     "start_time": "2024-03-20T10:53:06.050534400Z"
    }
   },
   "id": "eed48a623cc15fc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Różne funkcje aktywacji"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b1627c8cf55fa25"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "activation_functions = [heaviside, relu, leaky_relu, sigmoid, tanh]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:08.342072100Z",
     "start_time": "2024-03-20T10:53:08.315281300Z"
    }
   },
   "id": "cd6d456b99f8572e"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "  gate activation function  learning_rate epochs  \\\n0  AND           heaviside            0.3   1000   \n1  AND                relu            0.3   1000   \n2  AND          leaky_relu            0.3   1000   \n3  AND             sigmoid            0.3   1000   \n4  AND                tanh            0.3   1000   \n\n                                     weights                   bias  \\\n0  [0.6097627007854649, 0.34303787327448393]  [-0.8794473247856713]   \n1   [0.9999999999999998, 0.9999999999999997]  [-0.9999999999999997]   \n2   [0.9921414538310408, 0.9891944990176812]  [-0.9823182711198418]   \n3     [7.833260266400745, 7.827009109782254]  [-11.905421979318573]   \n4   [0.7887429603477558, 0.6762061466965057]  [-0.3943714801738777]   \n\n                 predictions      expected                      errors  \n0       [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]        [0.0, 0.0, 0.0, 0.0]  \n1       [0.0, 0.0, 0.0, 1.0]  [0, 0, 0, 1]       [0.0, 0.0, 0.0, -0.0]  \n2   [-0.01, 0.01, 0.01, 1.0]  [0, 0, 0, 1]   [-0.01, 0.01, 0.01, -0.0]  \n3    [0.0, 0.02, 0.02, 0.98]  [0, 0, 0, 1]    [0.0, 0.02, 0.02, -0.02]  \n4  [-0.38, 0.27, 0.38, 0.79]  [0, 0, 0, 1]  [-0.38, 0.27, 0.38, -0.21]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gate</th>\n      <th>activation function</th>\n      <th>learning_rate</th>\n      <th>epochs</th>\n      <th>weights</th>\n      <th>bias</th>\n      <th>predictions</th>\n      <th>expected</th>\n      <th>errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AND</td>\n      <td>heaviside</td>\n      <td>0.3</td>\n      <td>1000</td>\n      <td>[0.6097627007854649, 0.34303787327448393]</td>\n      <td>[-0.8794473247856713]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AND</td>\n      <td>relu</td>\n      <td>0.3</td>\n      <td>1000</td>\n      <td>[0.9999999999999998, 0.9999999999999997]</td>\n      <td>[-0.9999999999999997]</td>\n      <td>[0.0, 0.0, 0.0, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.0, 0.0, -0.0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AND</td>\n      <td>leaky_relu</td>\n      <td>0.3</td>\n      <td>1000</td>\n      <td>[0.9921414538310408, 0.9891944990176812]</td>\n      <td>[-0.9823182711198418]</td>\n      <td>[-0.01, 0.01, 0.01, 1.0]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[-0.01, 0.01, 0.01, -0.0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AND</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>1000</td>\n      <td>[7.833260266400745, 7.827009109782254]</td>\n      <td>[-11.905421979318573]</td>\n      <td>[0.0, 0.02, 0.02, 0.98]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[0.0, 0.02, 0.02, -0.02]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AND</td>\n      <td>tanh</td>\n      <td>0.3</td>\n      <td>1000</td>\n      <td>[0.7887429603477558, 0.6762061466965057]</td>\n      <td>[-0.3943714801738777]</td>\n      <td>[-0.38, 0.27, 0.38, 0.79]</td>\n      <td>[0, 0, 0, 1]</td>\n      <td>[-0.38, 0.27, 0.38, -0.21]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AND\n",
    "df_af_and = pd.DataFrame(columns=columns)\n",
    "\n",
    "for af in activation_functions:\n",
    "    model_and = SigmoidNeuron(2, learning_rate=0.3, activation_function=af)\n",
    "    model_and.train(AND_inputs, AND_labels, epochs=1000)\n",
    "    df_af_and = df_af_and._append({'gate': 'AND', 'activation function': af.__name__, 'learning_rate': 0.3, 'epochs': 1000, 'weights': model_and.weights, 'bias': model_and.bias, 'predictions': np.round(model_and.feedforward(AND_inputs), 2), 'expected': AND_labels, 'errors': np.round(model_and.feedforward(AND_inputs) - AND_labels, 2)}, ignore_index=True)\n",
    "    \n",
    "df_af_and"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:09.058152900Z",
     "start_time": "2024-03-20T10:53:08.331731900Z"
    }
   },
   "id": "c8f69a4b1d24af0a"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "  gate activation function  learning_rate epochs  \\\n0   OR           heaviside            0.3   1000   \n1   OR                relu            0.3   1000   \n2   OR          leaky_relu            0.3   1000   \n3   OR             sigmoid            0.3   1000   \n4   OR                tanh            0.3   1000   \n\n                                     weights                     bias  \\\n0    [0.309762700785465, 0.3430378732744839]   [-0.27944732478567125]   \n1  [0.28571428571428564, 0.3928571428571428]    [0.35714285714285715]   \n2  [0.28571428571428564, 0.3928571428571428]    [0.35714285714285715]   \n3     [9.047619812713735, 9.051559097189308]     [-4.058605842307561]   \n4   [3.5296696083207535, 3.5324611952368996]  [0.0034198910381548265]   \n\n                predictions      expected                      errors  \n0      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]        [0.0, 0.0, 0.0, 0.0]  \n1  [0.36, 0.75, 0.64, 1.04]  [0, 1, 1, 1]  [0.36, -0.25, -0.36, 0.04]  \n2  [0.36, 0.75, 0.64, 1.04]  [0, 1, 1, 1]  [0.36, -0.25, -0.36, 0.04]  \n3   [0.02, 0.99, 0.99, 1.0]  [0, 1, 1, 1]  [0.02, -0.01, -0.01, -0.0]  \n4      [0.0, 1.0, 1.0, 1.0]  [0, 1, 1, 1]     [0.0, -0.0, -0.0, -0.0]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gate</th>\n      <th>activation function</th>\n      <th>learning_rate</th>\n      <th>epochs</th>\n      <th>weights</th>\n      <th>bias</th>\n      <th>predictions</th>\n      <th>expected</th>\n      <th>errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>OR</td>\n      <td>heaviside</td>\n      <td>0.3</td>\n      <td>1000</td>\n      <td>[0.309762700785465, 0.3430378732744839]</td>\n      <td>[-0.27944732478567125]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, 0.0, 0.0, 0.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>OR</td>\n      <td>relu</td>\n      <td>0.3</td>\n      <td>1000</td>\n      <td>[0.28571428571428564, 0.3928571428571428]</td>\n      <td>[0.35714285714285715]</td>\n      <td>[0.36, 0.75, 0.64, 1.04]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.36, -0.25, -0.36, 0.04]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>OR</td>\n      <td>leaky_relu</td>\n      <td>0.3</td>\n      <td>1000</td>\n      <td>[0.28571428571428564, 0.3928571428571428]</td>\n      <td>[0.35714285714285715]</td>\n      <td>[0.36, 0.75, 0.64, 1.04]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.36, -0.25, -0.36, 0.04]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>OR</td>\n      <td>sigmoid</td>\n      <td>0.3</td>\n      <td>1000</td>\n      <td>[9.047619812713735, 9.051559097189308]</td>\n      <td>[-4.058605842307561]</td>\n      <td>[0.02, 0.99, 0.99, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.02, -0.01, -0.01, -0.0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>OR</td>\n      <td>tanh</td>\n      <td>0.3</td>\n      <td>1000</td>\n      <td>[3.5296696083207535, 3.5324611952368996]</td>\n      <td>[0.0034198910381548265]</td>\n      <td>[0.0, 1.0, 1.0, 1.0]</td>\n      <td>[0, 1, 1, 1]</td>\n      <td>[0.0, -0.0, -0.0, -0.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR\n",
    "df_af_or = pd.DataFrame(columns=columns)\n",
    "\n",
    "for af in activation_functions:\n",
    "    model_or = SigmoidNeuron(2, learning_rate=0.3, activation_function=af)\n",
    "    model_or.train(OR_inputs, OR_labels, epochs=1000)\n",
    "    df_af_or = df_af_or._append({'gate': 'OR', 'activation function': af.__name__, 'learning_rate': 0.3, 'epochs': 1000, 'weights': model_or.weights, 'bias': model_or.bias, 'predictions': np.round(model_or.feedforward(OR_inputs), 2), 'expected': OR_labels, 'errors': np.round(model_or.feedforward(OR_inputs) - OR_labels, 2)}, ignore_index=True)\n",
    "\n",
    "df_af_or"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T10:53:09.812621600Z",
     "start_time": "2024-03-20T10:53:09.058152900Z"
    }
   },
   "id": "5d796431a3f5b46"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Wnioski"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "858f717eda26cec5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "W przypadku neuronu sigmoidalnego znacznie lepiej widać istotę parametrów `learning_rate` i `epochs`. Wartość `learning_rate` służy do określenia jak bardzo wagi i bias są aktualizowane w każdej iteracji. Dla małych wartości `learning_rate` model uczy się wolniej (przez co będzie potrzebował więcej epok, aby dobrze się wytrenować), dla większych wartości `learning_rate` model uczy się szybciej (ale istnieje ryzyko, że wartość może być zbyt duża, co doprowadzi do tego, że nie będziemy w stanie dojść do optymalnego rozwiązania). Parametr `epochs` natomiast określa, podobnie jak to było w przypadku perceptronu, ile razy model ma przejść przez cały zbiór uczący. Im większa wartość, tym więcej iteracji model na dopasowanie się do danych. Powyższe obserwacje pokazują, że zbyt mała liczba epok może prowadzić do niedouczenia, co jest zjawiskiem niepożądanym. Oba te parametry są kluczowe dla osiągnięcia dobrych wyników w uczeniu maszynowym i aby efektywnie i szybko uczyć modele, niezbędne jest odpowiednie dobranie ich wartości."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe66eb31dfc87734"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e70e87795e1db5c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
